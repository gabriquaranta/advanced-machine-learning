====================================================================================================
LR = 1e-2            ### The initial Learning Rate
MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD
WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default
NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)
STEP_SIZE = 15       ### How many epochs before decreasing learning rate (if using a step-down policy)
GAMMA = 0.01         ### Multiplicative factor for learning rate step-down
====================================================================================================
Pretained weights (+ ImageNetâ€™s mean and standard deviation) on ImageNet finetuned on Caltech:
- transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
- net = alexnet(weights="DEFAULT")
====================================================================================================
Only Fully connected layers are trained (others frozen):
    parameters_to_optimize=[]
    for name, param in net.named_parameters():
        if "classifier" in name:  
            parameters_to_optimize.append(param) # optimize fully connected
        else:
            param.requires_grad = False # freeze not fully connnected
====================================================================================================
TRAINING
    Starting epoch 1/30, LR = [0.01]
    Step 0, Loss 0.030126702040433884
    Step 10, Loss 0.03745283931493759
    Starting epoch 2/30, LR = [0.01]
    Step 20, Loss 0.025698406621813774
    Step 30, Loss 0.041548218578100204
    Starting epoch 3/30, LR = [0.01]
    Step 40, Loss 0.03891557455062866
    Starting epoch 4/30, LR = [0.01]
    Step 50, Loss 0.022928748279809952
    Step 60, Loss 0.021064652130007744
    Starting epoch 5/30, LR = [0.01]
    Step 70, Loss 0.032163746654987335
    Starting epoch 6/30, LR = [0.01]
    Step 80, Loss 0.030676767230033875
    Step 90, Loss 0.016601938754320145
    Starting epoch 7/30, LR = [0.01]
    Step 100, Loss 0.01107027381658554
    Step 110, Loss 0.01347990520298481
    Starting epoch 8/30, LR = [0.01]
    Step 120, Loss 0.009937948547303677
    Starting epoch 9/30, LR = [0.01]
    Step 130, Loss 0.02428830787539482
    Step 140, Loss 0.007155788596719503
    Starting epoch 10/30, LR = [0.01]
    Step 150, Loss 0.008911759592592716
    Starting epoch 11/30, LR = [0.01]
    Step 160, Loss 0.010817389003932476
    Step 170, Loss 0.006495486944913864
    Starting epoch 12/30, LR = [0.01]
    Step 180, Loss 0.009129677899181843
    Step 190, Loss 0.01708606258034706
    Starting epoch 13/30, LR = [0.01]
    Step 200, Loss 0.008292547427117825
    Starting epoch 14/30, LR = [0.01]
    Step 210, Loss 0.0135186230763793
    Step 220, Loss 0.022618649527430534
    Starting epoch 15/30, LR = [0.01]
    Step 230, Loss 0.009091642685234547
    Starting epoch 16/30, LR = [0.0001]
    Step 240, Loss 0.009434657171368599
    Step 250, Loss 0.018225345760583878
    Starting epoch 17/30, LR = [0.0001]
    Step 260, Loss 0.03231162577867508
    Step 270, Loss 0.005412241909652948
    Starting epoch 18/30, LR = [0.0001]
    Step 280, Loss 0.018511921167373657
    Starting epoch 19/30, LR = [0.0001]
    Step 290, Loss 0.005340853240340948
    Step 300, Loss 0.007031967863440514
    Starting epoch 20/30, LR = [0.0001]
    Step 310, Loss 0.005809472408145666
    Starting epoch 21/30, LR = [0.0001]
    Step 320, Loss 0.008074852637946606
    Step 330, Loss 0.00502666225656867
    Starting epoch 22/30, LR = [0.0001]
    Step 340, Loss 0.006779377348721027
    Step 350, Loss 0.007504985202103853
    Starting epoch 23/30, LR = [0.0001]
    Step 360, Loss 0.030489515513181686
    Starting epoch 24/30, LR = [0.0001]
    Step 370, Loss 0.009081332013010979
    Step 380, Loss 0.011664176359772682
    Starting epoch 25/30, LR = [0.0001]
    Step 390, Loss 0.009008077904582024
    Starting epoch 26/30, LR = [0.0001]
    Step 400, Loss 0.007039674557745457
    Step 410, Loss 0.005693455226719379
    Starting epoch 27/30, LR = [0.0001]
    Step 420, Loss 0.006831175182014704
    Step 430, Loss 0.005579920019954443
    Starting epoch 28/30, LR = [0.0001]
    Step 440, Loss 0.011928359977900982
    Starting epoch 29/30, LR = [0.0001]
    Step 450, Loss 0.006498944014310837
    Step 460, Loss 0.005955231375992298
    Starting epoch 30/30, LR = [0.0001]
    Step 470, Loss 0.006008512806147337

VALIDATION
    Validation Accuracy: 0.8492392807745505

TESTING
    Test Accuracy: 0.867611475976495

COMPARISON
ImageNet + Finetune Base Model:
- Validation Accuracy: 0.8333333333333334
- Test Accuracy: 0.8603525751814726

ImageNet + Finetune Model 3:
- Validation Accuracy: 0.8533886583679114
- Test Accuracy: 0.8627722087798133

ImageNet + Finetune Model 3 Connected Only:
- Validation Accuracy: 0.8492392807745505
- Test Accuracy: 0.867611475976495