====================================================================================================
LR = 1e-2            ### The initial Learning Rate
MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD
WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default
NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)
STEP_SIZE = 15       ### How many epochs before decreasing learning rate (if using a step-down policy)
GAMMA = 0.01         ### Multiplicative factor for learning rate step-down
====================================================================================================
Pretained weights (+ ImageNetâ€™s mean and standard deviation) on ImageNet finetuned on Caltech:
- transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
- net = alexnet(weights="DEFAULT")
====================================================================================================
Only Fully connected layers are trained (others frozen):
    parameters_to_optimize=[]
    for name, param in net.named_parameters():
        if "classifier" not in name:  
            parameters_to_optimize.append(param) # optimize conv 
            param.requires_grad = True
        else:
            param.requires_grad = False # freeze fully connnected
====================================================================================================
TRAINING
    Starting epoch 1/30, LR = [0.01]
    Step 0, Loss 4.796591281890869
    Step 10, Loss 4.326467990875244
    Starting epoch 2/30, LR = [0.01]
    Step 20, Loss 3.774698257446289
    Step 30, Loss 3.4367265701293945
    Starting epoch 3/30, LR = [0.01]
    Step 40, Loss 3.446669340133667
    Starting epoch 4/30, LR = [0.01]
    Step 50, Loss 3.05985164642334
    Step 60, Loss 3.0688164234161377
    Starting epoch 5/30, LR = [0.01]
    Step 70, Loss 3.1787660121917725
    Starting epoch 6/30, LR = [0.01]
    Step 80, Loss 3.0448789596557617
    Step 90, Loss 2.7467997074127197
    Starting epoch 7/30, LR = [0.01]
    Step 100, Loss 2.7508296966552734
    Step 110, Loss 2.706470012664795
    Starting epoch 8/30, LR = [0.01]
    Step 120, Loss 2.9847543239593506
    Starting epoch 9/30, LR = [0.01]
    Step 130, Loss 2.580824851989746
    Step 140, Loss 2.5386300086975098
    Starting epoch 10/30, LR = [0.01]
    Step 150, Loss 2.489994525909424
    Starting epoch 11/30, LR = [0.01]
    Step 160, Loss 2.1803951263427734
    Step 170, Loss 2.5137364864349365
    Starting epoch 12/30, LR = [0.01]
    Step 180, Loss 2.1269137859344482
    Step 190, Loss 2.1333160400390625
    Starting epoch 13/30, LR = [0.01]
    Step 200, Loss 2.164254665374756
    Starting epoch 14/30, LR = [0.01]
    Step 210, Loss 2.3352746963500977
    Step 220, Loss 1.9916893243789673
    Starting epoch 15/30, LR = [0.01]
    Step 230, Loss 1.873287558555603
    Starting epoch 16/30, LR = [0.0001]
    Step 240, Loss 1.7813082933425903
    Step 250, Loss 1.9759745597839355
    Starting epoch 17/30, LR = [0.0001]
    Step 260, Loss 1.757838487625122
    Step 270, Loss 1.6568034887313843
    Starting epoch 18/30, LR = [0.0001]
    Step 280, Loss 1.7705693244934082
    Starting epoch 19/30, LR = [0.0001]
    Step 290, Loss 1.8176592588424683
    Step 300, Loss 1.8568675518035889
    Starting epoch 20/30, LR = [0.0001]
    Step 310, Loss 2.0757648944854736
    Starting epoch 21/30, LR = [0.0001]
    Step 320, Loss 1.5546233654022217
    Step 330, Loss 1.7409775257110596
    Starting epoch 22/30, LR = [0.0001]
    Step 340, Loss 1.9233806133270264
    Step 350, Loss 1.8516182899475098
    Starting epoch 23/30, LR = [0.0001]
    Step 360, Loss 1.7601840496063232
    Starting epoch 24/30, LR = [0.0001]
    Step 370, Loss 1.777266025543213
    Step 380, Loss 1.6134154796600342
    Starting epoch 25/30, LR = [0.0001]
    Step 390, Loss 1.6744645833969116
    Starting epoch 26/30, LR = [0.0001]
    Step 400, Loss 1.6919043064117432
    Step 410, Loss 1.8691725730895996
    Starting epoch 27/30, LR = [0.0001]
    Step 420, Loss 1.6679424047470093
    Step 430, Loss 1.5351496934890747
    Starting epoch 28/30, LR = [0.0001]
    Step 440, Loss 1.7146352529525757
    Starting epoch 29/30, LR = [0.0001]
    Step 450, Loss 1.6095867156982422
    Step 460, Loss 1.540731430053711
    Starting epoch 30/30, LR = [0.0001]
    Step 470, Loss 1.971238613128662

VALIDATION
    Validation Accuracy: 0.5532503457814661

TESTING
    Test Accuracy: 0.5620463187003111

COMPARISON
ImageNet + Finetune Base Model:
- Validation Accuracy: 0.8333333333333334
- Test Accuracy: 0.8603525751814726

ImageNet + Finetune Model 3:
- Validation Accuracy: 0.8533886583679114
- Test Accuracy: 0.8627722087798133

ImageNet + Finetune Model 3 Connected Only:
- Validation Accuracy: 0.8492392807745505
- Test Accuracy: 0.867611475976495

ImageNet + Finetune Model 3 Convolutionl Only:
- Validation Accuracy: 0.5532503457814661
- Test Accuracy: 0.5620463187003111